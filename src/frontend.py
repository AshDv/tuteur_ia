import sys
import os
import base64
import streamlit as st
from io import BytesIO
from app import ConversationAgent
from quiz_agent import QuizAgent
from utils import DocumentProcessor

current_dir = os.path.dirname(__file__)
project_root = os.path.abspath(os.path.join(current_dir, '..'))
context_text = ""
difficulty = ""

if project_root not in sys.path:
    sys.path.append(project_root)

from resources.config import LLM_MODELS

if "selected_model" not in st.session_state:
    st.session_state.selected_model = LLM_MODELS[0]
VISION_MODEL = "meta-llama/llama-4-scout-17b-16e-instruct"


def initialize_session():
    """Initialise tous les agents et les variables de session."""
    
    # 1. Initialisation de l'√©tat du quiz
    if "quiz_manager" not in st.session_state:
        st.session_state.quiz_manager = QuizAgent()
    
    # 2. Initialisation de l'agent principal (avec injection de d√©pendance)
    if "conversation_agent" not in st.session_state:
        st.session_state.conversation_agent = ConversationAgent(
            quiz_agent=st.session_state.quiz_manager
        )
    
    # Variables pour le frontal
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = LLM_MODELS[0]
    if "course_text_content" not in st.session_state:
        st.session_state.course_text_content = ""
    if "image_base64_url" not in st.session_state:
        st.session_state.image_base64_url = None

# --- FONCTIONS D'AFFICHAGE DU FLUX QUIZ ---

def render_start_interface(agent: ConversationAgent, quiz_manager: QuizAgent):
    """Affiche les contr√¥les pour d√©marrer le quiz et la zone de conversation standard."""
    
    st.header("D√©marrez un cycle de r√©vision.")
    
    # R√©cup√©ration du sujet si un PDF a √©t√© charg√©
    default_topic = "le cours ci-joint" if st.session_state.course_text_content else "un sujet libre"
    
    st.markdown("### Configuration du Quiz")
    
    c1, c2, c3, c4 = st.columns([3, 1, 1, 1])
    with c1:
        topic = st.text_input("Sujet de l'√©valuation", value=default_topic, 
                            placeholder="Ex: La R√©volution Fran√ßaise")
    with c2:
        num_questions = st.slider("Nb Questions", 1, 20, 3)
    with c3:
        st.session_state.selected_model = st.selectbox(
            "Mod√®le", 
            options=LLM_MODELS,
            index=0,
            key='llm_select_quiz'
        )
    with c4:
        difficulty = st.selectbox("Niveau", ["D√©butant", "Moyen", "Expert"])
    
    if st.button("üöÄ G√©n√©rer l'√©valuation") and topic:
        quiz_manager.set_state('generating')
        st.rerun() # Recharger pour afficher le spinner


def render_questioning_interface(agent: ConversationAgent, quiz_manager: QuizAgent):
    """Affiche la question en cours et le formulaire de r√©ponse."""
    
    q_data = quiz_manager.read_current_question()
    q_index = quiz_manager.read_quiz_length() - (quiz_manager.read_quiz_length() - quiz_manager.read_current_question_index())
    
    # Affichage de l'√©nonc√©
    st.header(f"Question {q_index + 1}/{quiz_manager.read_quiz_length()}")
    st.subheader(q_data['question'])
    
    user_answer = ""
    
    # Formulaire de soumission
    with st.form("current_question_form", clear_on_submit=True):
        
        # Logique de l'interface QCM vs OUVERTE
        if q_data['type'] == 'qcm':
            # Interface QCM : Radio buttons
            choices_with_letters = [f"{chr(65 + i)}. {choice}" for i, choice in enumerate(q_data['choices'])]
            
            # Stocke la r√©ponse compl√®te (ex: "A. Choix 1")
            user_choice_with_letter = st.radio(
                "Choisis ta r√©ponse :",
                options=choices_with_letters, 
                index=None,
                key='qcm_answer'
            )
            if user_choice_with_letter:
                # On stocke uniquement la lettre (A, B, C, D) pour la correction
                user_answer = user_choice_with_letter[0] 
                
        else: # type == 'open'
            # Interface Ouverte : Zone de texte
            user_answer = st.text_area("Ta r√©ponse r√©dig√©e :", key='open_answer')
            
        
        # Bouton de soumission
        if st.form_submit_button("Soumettre la R√©ponse et Passer √† la Suivante"):
            if not user_answer:
                st.warning("Veuillez saisir ou choisir une r√©ponse, Sensei n'aime pas le vide.")
                return 

            # Enregistre la r√©ponse et avance l'√©tat (sans correction imm√©diate)
            quiz_manager.record_answer_and_advance(user_answer)
            st.rerun() # Recharger pour passer √† la question suivante ou √† la fin

def render_final_review_interface(agent: ConversationAgent, quiz_manager: QuizAgent):
    """D√©clenche la correction finale par le LLM et passe √† l'affichage des r√©sultats."""
    
    # Utilise le mod√®le s√©lectionn√© par l'utilisateur pour le quiz
    model_id = st.session_state.selected_model
    
    st.header("Correction en Cours...")
    st.info("Ma√Ætre Splinter √©value la qualit√© de votre pratique. Cela peut prendre quelques instants pour les questions ouvertes.")
    
    with st.spinner("√âvaluation finale par le tuteur IA..."):
        # Appel de la m√©thode qui boucle et corrige toutes les r√©ponses
        quiz_manager.finalize_quiz_results(agent, model=model_id)
        
    st.rerun() # Passe √† l'√©tat 'finished'

def render_finished_interface(quiz_manager: QuizAgent):
    """Affiche le score final et les corrections d√©taill√©es."""
    
    total = quiz_manager.read_quiz_length()
    score = quiz_manager.read_score()
    
    st.header("üî• Fin de l'√âvaluation üî•")
    st.success(f"### üèÜ Score Final : {score} / {total}")
    
    st.markdown("---")
    st.subheader("Correction D√©taill√©e de Ma√Ætre Splinter :")
    
    # Boucle sur les r√©sultats corrig√©s
    for i, result in enumerate(quiz_manager.read_results()):
        q_data = result['question_data']
        correction = result['correction']
        
        # Affichage du statut
        status_icon = "‚úÖ" if correction['score'] == 1 else "‚ùå"
        st.markdown(f"#### {status_icon} Question {i+1}: {q_data['question']}")
        
        st.markdown(f"**Votre r√©ponse :** *{result['user_answer']}*")
        
        # Affichage du feedback (ton de Ma√Ætre Splinter)
        st.info(f"**Feedback du Sensei :** {correction['feedback']}")

        if q_data['type'] == 'qcm':
            # Afficher la bonne lettre si c'√©tait un QCM
            st.caption(f"R√©ponse attendue : {q_data['correct_identifier']}")
            
        st.write("---")

    if st.button("ü•ã Recommencer l'Entra√Ænement"):
        quiz_manager.delete_quiz()
        st.rerun()

# --- FONCTIONS D'AFFICHAGE DU FLUX DE CHAT ---

def render_chat_history(agent: ConversationAgent):
    """Affiche l'historique de la conversation, y compris les images."""
    
    # L'historique d'affichage est conserv√© dans agent.history
    for message in agent.history:
        if message["role"] != "system":
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # Affichage de l'image si la cl√© existe (stock√©e en Data URI)
                if "image_url" in message and message["image_url"]:
                    # Utiliser width pour √©viter le warning de d√©pr√©ciation
                    st.image(message["image_url"], width=300) 

def render_chat_input(agent: ConversationAgent):
    """G√®re l'entr√©e utilisateur pour le mode conversationnel/vision."""
    
    # D√©tecter si l'utilisateur a charg√© une image
    uploaded_image_file = st.session_state.get('img_uploader')
    
    if user_input := st.chat_input("Pose ta question ou demande un r√©sum√© √† Splinter..."):
        
        # R√©cup√©ration des donn√©es pour l'appel
        context_text = st.session_state.course_text_content
        model_id = st.session_state.selected_model
        image_url_full = None
        
        # Traitement de l'image si elle est pr√©sente
        if uploaded_image_file:
            # Assurez-vous que l'objet fichier est r√©initialis√© avant l'encodage
            uploaded_image_file.seek(0)
            
            # Encoder pour l'API
            image_b64_raw = base64.b64encode(uploaded_image_file.read()).decode('utf-8')
            mime_type = uploaded_image_file.type
            
            # Pr√©parer l'URL d'affichage
            image_url_full = f"data:{mime_type};base64,{image_b64_raw}"
            
        with st.spinner("Splinter r√©fl√©chit..."):
            
            if uploaded_image_file:
                # --- MODE VISION ---
                response = agent.ask_vision_model(
                    user_interaction=user_input,
                    image_b64=image_b64_raw,
                    mime_type=mime_type,
                    image_url_for_display=image_url_full,
                    model=VISION_MODEL # Vision utilise un mod√®le sp√©cifique
                )
            else:
                # --- MODE CHAT/DOCUMENT ---
                response = agent.ask_llm(
                    user_interaction=user_input,
                    model=model_id,
                    context_text=context_text # Passage du contenu du PDF
                )
        
        # R√©initialisation du file uploader (pour ne pas r√©utiliser l'image)
        if 'img_uploader' in st.session_state:
            del st.session_state['img_uploader']
            
        st.rerun()


# --- FEN√äTRE PRINCIPALE ---

def run_app():
    """Point d'entr√©e principal de l'application Streamlit."""
    
    st.set_page_config(page_title="Splinter - Tuteur IA", page_icon="üê≠", layout="wide")
    initialize_session()
    
    agent = st.session_state.conversation_agent
    quiz_manager = st.session_state.quiz_manager
    current_state = quiz_manager.read_state()
    
    # --- BARRE LAT√âRALE ---
    with st.sidebar:
        # ... (image, titre)
        st.title("üìö Outils d'Entra√Ænement")
        
        uploaded_pdf_list = st.file_uploader(
            "Fichiers PDF (Cours - Max. 5)", 
            type="pdf", 
            key="pdf_uploader",
            accept_multiple_files=True
        )
        
        # Logique de lecture des PDF
        if uploaded_pdf_list:
            
            # Limiter √† 5 fichiers
            uploaded_pdf_list = uploaded_pdf_list[:5]
            
            # üõë R√©initialisation avant de commencer la lecture
            st.session_state.course_text_content = ""
            
            with st.spinner(f"Analyse de {len(uploaded_pdf_list)} documents..."):
                
                all_text_with_names = []
                total_chars = 0
                
                for pdf_file in uploaded_pdf_list:
                    # Extraction du texte
                    text = DocumentProcessor.extract_text_from_pdf(pdf_file)
                    
                    # üí° Utilisation de l'impl√©mentation am√©lior√©e (avec le nom de fichier)
                    separator_and_text = f"\n--- Fichier : {pdf_file.name} ---\n{text}"
                    all_text_with_names.append(separator_and_text)
                    total_chars += len(text)
                
                # Concat√©ner tout le contenu dans la session state
                st.session_state.course_text_content = "\n".join(all_text_with_names)
                
                st.success(f"{len(uploaded_pdf_list)} PDF(s) charg√©s en m√©moire !")
                st.caption(f"Total : {total_chars} caract√®res.")
        
        # Si la liste est vide (l'utilisateur a retir√© les fichiers), on vide la session state
        elif 'course_text_content' in st.session_state:
            st.session_state.course_text_content = ""
        
        st.divider()

        # 2. Upload Image (GESTION MULTIPLE JUSQU'√Ä 5)
        # üí° Changement 2 : Utilisation de accept_multiple_files=True
        uploaded_image_list = st.file_uploader(
            "Sch√©mas/Graphiques (pour analyse vision - Max. 5)", 
            type=["png", "jpg", "jpeg"], 
            key="img_uploader",
            accept_multiple_files=True # Permet de charger plusieurs images
        )
        
        # Logique de lecture des images
        # Nous allons stocker une liste d'URLs Base64 dans la session state
        st.session_state.image_base64_url = []
        if uploaded_image_list:
            
            # Limiter √† 5 fichiers
            if len(uploaded_image_list) > 5:
                st.warning("Seuls les 5 premi√®res images seront trait√©es.")
                uploaded_image_list = uploaded_image_list[:5]
                
            for img_file in uploaded_image_list:
                # Utiliser la fonction pour encoder chaque image
                base64_url = DocumentProcessor.convert_image_to_base64(img_file)
                if base64_url:
                    st.session_state.image_base64_url.append(base64_url)
                    st.image(img_file, width=150) # Affichage de l'aper√ßu dans la sidebar
            
            if st.session_state.image_base64_url:
                st.success(f"{len(st.session_state.image_base64_url)} image(s) pr√™te(s) !")

    
    st.title("üê≠ Ma√Ætre Splinter - Tuteur IA")
    
    # --- LOGIQUE CONDITIONNELLE DU FLUX ---
    
    if current_state in ['start', 'questioning', 'final_review', 'finished']:
        tab_chat, tab_quiz = st.tabs(["üí¨ Discussion & Vision", "üìù Quiz Dynamique"])
    else:
        # Afficher uniquement le tab quiz pendant la g√©n√©ration pour ne pas perdre le focus
        tab_chat, tab_quiz = st.tabs(["üí¨ Discussion & Vision", "üìù Quiz Dynamique"])
        
    
    with tab_chat:
        st.header("Discours & Sagesse du Ma√Ætre")
        
        # Afficher la s√©lection du mod√®le LLM ici pour le mode conversationnel
        st.session_state.selected_model = st.selectbox(
            "Mod√®le de Conversation", 
            options=LLM_MODELS,
            index=0,
            key='llm_select_chat'
        )
        
        # Afficher l'historique
        render_chat_history(agent)
        
        # Afficher le chat input (uniquement si le quiz n'est pas actif)
        if current_state == 'start':
            render_chat_input(agent)
        elif current_state != 'start':
            st.warning("Veuillez compl√©ter ou annuler le quiz avant de commencer une nouvelle discussion.")


    with tab_quiz:
        
        if current_state == 'start':
            render_start_interface(agent, quiz_manager)

        elif current_state == 'generating':
            with st.spinner("Cr√©ation du questionnaire par le Ma√Ætre..."):
                model_id = st.session_state.selected_model
                topic_input = st.session_state.get('topic', 'sujet libre')
                num_questions = st.session_state.get('num_questions', 3)
                
                # Assurez-vous que le sujet, nb questions et mod√®le sont pass√©s correctement
                success = st.session_state.conversation_agent.generate_quiz(
                    topic=topic_input, 
                    n_questions=num_questions, 
                    model=model_id,
                    context_instruction=context_text,
                    difficulty=difficulty
                )
                
                if not success:
                    st.error("‚ùå √âchec de la g√©n√©ration du quiz. V√©rifiez le sujet ou le format JSON.")
                    quiz_manager.set_state('start')
                    
                st.rerun() # Passe √† l'√©tat 'questioning'

        elif current_state == 'questioning':
            render_questioning_interface(agent, quiz_manager)

        elif current_state == 'final_review':
            render_final_review_interface(agent, quiz_manager)

        elif current_state == 'finished':
            render_finished_interface(quiz_manager)


# --- EX√âCUTION DU PROGRAMME ---
if __name__ == "__main__":
    run_app()